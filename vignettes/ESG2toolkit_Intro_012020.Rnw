%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{ESGtoolkit}
\documentclass[a4paper]{article}
\usepackage[british]{babel}
\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[colorlinks,linkcolor=red, citecolor=blue, urlcolor=red]{hyperref}
\usepackage{xcolor}
\usepackage{url}
\usepackage{float}
\usepackage{amssymb,amsfonts,amsmath}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage[authoryear]{natbib}
\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyhead[C]{\code{ESGtoolkit}, tools for stochastic simulation $\bullet$ January 2020} % 
\date{}
\newcommand{\CC}{\ensuremath{\mathbb{C}} }
\newcommand{\NN}{\ensuremath{\mathbb{N}} }
\newcommand{\RR}{\ensuremath{\mathbb{R}} }
\newcommand{\QQ}{\ensuremath{\mathbb{Q}} }
\newcommand{\EE}{\ensuremath{\mathbb{E}} }
\newcommand{\PP}{\ensuremath{\mathbb{P}} }
\newcommand{\noi}{\noindent}
\newcommand{\II}{\mbox{\large 1\hskip -0,353em 1}}
\newcommand{\dps}{\displaystyle}
\newcommand{\ms}{\medskip}
\newcommand{\itb}{\ms\item[$\bullet$]}
\newcommand{\itm}{\ms\item}
\newcommand{\pkg}[1]{{\normalfont\fontseries{b}\selectfont #1}}
\newcommand{\proglang}[1]{\textsf{#1}}
\newcommand{\code}[1]{\mbox{\texttt{#1}}}
\newcommand{\MN}{\mathcal{N}}
\newcommand{\MM}{\mathcal{M}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\GG}{\mathcal{G}}
\newcommand{\HH}{\mathcal{H}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\AT}{\mathcal{A}}


\begin{document}

\title{\bf{\code{ESGtoolkit}, a tool for stochastic simulation (\code{v0.2.0})}} % Article title
\author{
Thierry Moudiki\\ % Your name
%\url{http://thierrymoudiki.wordpress.com}\\ % Your institution
\today{}
%\href{mailto:thierry.moudiki@gmail.com}{thierry.moudiki@gmail.com} % Your email address
}
\maketitle

\tableofcontents

\newpage

\section{Overview}

\subsection{Context}

This package was initially developped for insurance in 2014. \textbf{If you're not working in insurance, this package is still relevant for stochastic simulation} in Finance, Economics, or Physics. In that case, you can start directly with \ref{sec:simdiff}. Oh, except maybe this paragraph: \ref{para}. 

\medskip

An \textit{Economic Scenario Generator} (ESG) is a tool for projection of plausible future paths for an insurer's financial risk factors. It helps in pricing its insurance products, and assessing current and future solvency. Two types of ESGs are generally needed, for different purposes : a \textit{real-world} ESG, and a  a \textit{market consistent} ESG.


\medskip

The aim of a real-world ESG is to produce projections of risk factors, whose distribution patterns are  coherent with the past distribution of those risk factors. Real-world scenarios are mainly used for the valuation of solvency capital requirements.  

\medskip

A market consistent ESG shall produce projections of risk factors that are coherent with market prices observed at the valuation date. Market consistent scenarios are mainly used for the best estimate valuation of technical reserves. 


\medskip

Hence, in real-world simulations the historical probability is used and in market consistent simulations, the projection of risk factors is made in a risk-neutral probability. A risk-neutral probability measure is a measure under which the discounted prices of assets are martingales.  

\medskip

A simple example of transitioning from a simulation under the historical probability to a simulation under a risk-neutral probability can be made by using the Black-Scholes model, a geometric Brownian motion. In a real-world simulation, we can assume that an asset evolves according to the following Stochastic Differential Equation (SDE) (with a drift $\mu$, a volatility $\sigma$, and $\left( W(t) \right)_{t \geq 0}$ being a standard brownian motion): 

\begin{equation}
dS(t) = \mu S(t) dt + \sigma S(t) dW(t)
\end{equation}

\medskip

Let $r$ be a constant risk-free rate. $e^{-rt}S(t)$, the discounted price of $S(t)$, will be a martingale if 
\begin{equation}
d(e^{-rt}S(t))
\end{equation}

is driftless. Applying Ito's formula to $e^{-rt}S(t)$, we have : 

\begin{eqnarray}
d(e^{-rt}S(t)) &=& -r e^{-rt} S(t) dt + e^{-rt} dS(t) - \frac{1}{2}.0 <dS(t), dS(t)>\\
               &=& -r e^{-rt} S(t) dt + e^{-rt} \mu S(t) dt + e^{-rt} S(t) \sigma dW(t) \\
               &=&  e^{-rt} S(t) \left[  (\mu - r) dt + \sigma dW(t) \right]
\end{eqnarray}

Thus, the drift vanishes iff $\mu = r$. That is, if our asset with price $S(t)$ at time $t$ rewards the risk-free rate $r$. Under this martingale probability measure, the asset price evolution over time can thus be re-written as:

\begin{equation}
dS(t) = r S(t) dt + \sigma S(t) dW^*(t)
\end{equation}
Where $\left(W^*(t)\right)_{t \geq 0}$ is a standard brownian motion under the chosen risk-neutral measure. 

\medskip

As we'll see in section \ref{sec:simdiff}, \code{ESGtoolkit} does not directly provide multiple asset models but instead, some building blocks for constructing a variety of these. Two main functions are therefore provided for his purpose: \code{simshocks}, \code{simdiff}. Other tools for statistical testing and visualization are presented as well.

\paragraph{As a reminder:}
\label{para}
There are no perfect models, and the more sophisticated doesn't necessarily mean the most judicious. To avoid possible disasters, it's important to know precisely the strengths and weaknesses of a model before using it.

\subsection{\code{simdiff}}
\label{sec:simdiff}

Let $(W(t))_{t \geq 0}$ be a standard brownian motion. \code{simdiff} makes simulations of a  diffusion process $(X(t))_{t \geq 0}$, which evolves according to the following equation: 

\begin{equation}
\label{eq:genericsde}
\textcolor{blue}{dX(t) = \mu(t, X(t)) dt + \sigma(t, X(t))} \textcolor{red}{dW(t)} + \textcolor{green}{\gamma(t, X(t-), J)dN(t)}
\end{equation}

\medskip

Actually, (Eq. \ref{eq:genericsde}) is a generic formulation of all \code{simdiff} models. {\bf Not all parts of this expression are required all the times}, but $\textcolor{blue}{\sigma(t, X(t))} \textcolor{red}{dW(t)}$, describing our process' volatility. Let's describe the other parts. 

\medskip

$\textcolor{green}{\gamma(t, X(t-), J) dN(t)}$ is optional, and not available for all the models. It contains jumps of the process, that occur according to a homogeneous Poisson process $(N(t))_{t \geq 0}$ with  intensity $\lambda$. The time elasped between two jumping times follows an exponential $\epsilon(\lambda)$ distribution; and the number of jumps of the process on $[0, t[$ follows a Poisson distribution $\mathcal{P}(\lambda t)$. The magnitude of the jumps is controlled by $J$.    

\medskip

Now, for the \textcolor{blue}{blue part} of (Eq. \ref{eq:genericsde}), we could have: 

\begin{itemize}

\item An Orsnstein-Uhlenbeck process; for \code{simdiff} used with parameter \newline \code{model = "OU"}, and parameters \code{theta1}, \code{theta2} and \code{theta3} provided (if \code{theta1} or \code{theta2} are  not necessary for building the model, they are to be provided and set to \code{0}):
\begin{eqnarray*}
\textcolor{blue}{\mu(t, X(t))} &=& (\theta_1 - \theta_2 X(t))\\
\textcolor{blue}{\sigma(t, X(t))} &=& \theta_3\\
\end{eqnarray*}

\item A Cox-Ingersoll-Ross process; for \code{simdiff} used with parameter \newline \code{model = "CIR"}, and parameters \code{theta1}, \code{theta2}, \code{theta3} provided (if \code{theta1} or \code{theta2} are  not necessary for building the model, they are to be provided and set to \code{0}) : 

\begin{eqnarray*}
\textcolor{blue}{\mu(t, X(t))} &=& (\theta_1 - \theta_2 X(t))\\
\textcolor{blue}{\sigma(t, X(t))} &=& \theta_3 \sqrt{X(t)}\\
\end{eqnarray*} 

\item A Geometric Brownian motion, or \textit{augmented} versions; for \code{simdiff} used with parameter \code{model = "GBM"}, and parameters \code{theta1}, \code{theta2}, \code{theta3} provided. For the sake of clarity, the argument \code{model} is set to \code{"GBM"}, but not only the Geometric Brownian motion with constant parameters is available. We could have : 

A Geometric Brownian Motion

\begin{eqnarray*}
\textcolor{blue}{\mu(t, X(t))} &=& \theta_1 X(t)\\
\textcolor{blue}{\sigma(t, X(t))} &=& \theta_2 X(t)\\ 
\end{eqnarray*}

A modified Geometric Brownian Motion, with time-varying drift and constant volatility

\begin{eqnarray*}
\textcolor{blue}{\mu(t, X(t))} &=& \theta_1(t) X(t)\\
\textcolor{blue}{\sigma(t, X(t))} &=& \theta_2 X(t)\\
\end{eqnarray*}

A modified Geometric Brownian Motion, with time-varying volatility and constant drift

\begin{eqnarray*}
\textcolor{blue}{\mu(t, X(t))} &=& \theta_1 X(t)\\ 
\textcolor{blue}{\sigma(t, X(t))} &=& \theta_2(t) X(t)\\
\end{eqnarray*}
\end{itemize}

It's technically possible to have both $\theta_1$ and $\theta_2$ varying with time (both provided as multivariate time series). But it's not advisable to do this, unless you know exactly why you're doing it. 

\medskip

Jumps are available only for \code{model = "GBM"}. The jumps arising from the Poisson process have a common magnitude $J = 1+Z$, whose distribution $\nu$ is either lognormal or double-exponential. Between two jumps, the process behaves like a Geometric Brownian motion, and at jumping times, it increases by $Z$\%. For lognormal jumps (Merton model), the distribution $\nu$ of $J$ is:
\begin{equation}
log(J) = log(1+Z) \sim \MN(log(1+\mu_Z) - \frac{\sigma_Z^2}{2}, \sigma_Z^2)
\end{equation}

For double exponential jumps (Kou's model), the distribution $\nu$ of $J$ is:

\begin{equation}
log(J) = log(1+Z) \sim \nu(dy) = p\frac{1}{\eta_u} e^{- \frac{1}{\eta_u}} \II_{y > 0} + (1-p)\frac{1}{\eta_d} e^{\frac{1}{\eta_d}} \II_{y < 0}
\end{equation}

Hence for taking jumps into account when \code{model = "GBM"}, optional parameters are to be provided to \code{simdiff}, namely:


\begin{itemize}
\item \code{lambda}: intensity of the Poisson process
\item \code{mu\underline{ }z}: average jump magnitude (only for {\bf lognormal} jumps)
\item \code{sigma\underline{ }z}: standard deviation of the jump magnitude (only for {\bf lognormal} jumps)
\item \code{p}: probability of positive jumps (only for {\bf double exponential} jumps)
\item \code{eta\underline{ }up}: the mean of positive jumps (only for {\bf double exponential} jumps)
\item \code{eta\underline{ }down}: the mean of negative jumps (only for {\bf double exponential} jumps)
\end{itemize}

\medskip

\code{simdiff}'s core loops are written in C++ \textit{via} \href{http://cran.r-project.org/web/packages/Rcpp/index.html}{Rcpp} because: speed.  Currently, for an Ornstein-Uhlenbeck process with \code{model = "OU"}, a Cox-Ingersoll-Ross process with \code{model = "CIR"}, or a geometric brownian motion with \code{model = "GBM"}, an exact simulation is used, which means there's no discretization of $(X(t))_{t \geq 0}$ on a time grid. You can also choose an \code{horizon} of projection and a sampling \code{frequency} (annual, semi-annual, quarterly $\ldots$). \code{simdiff}'s output is a time series object created by base \proglang{R} function \code{ts()}. Since this output is a \code{ts()} object, it means you can use function such as \code{window.ts} or \code{frequency} on it. 

\medskip

For a customized simulation of $\textcolor{red}{\epsilon} \sim \MN(0, 1)$ embedded in (Eq. \ref{eq:genericsde}) \textit{via} $\textcolor{red}{dW(t) = \epsilon dt}$, you can fill \code{simdiff}'s parameter \code{eps} with an output of function \code{simshocks}. \code{simshocks} is described in the next section, \ref{sec:simshocks}.


\subsection{\code{simshocks}}
\label{sec:simshocks}

\code{simshocks} is the complementary function to \code{simdiff}, with which you can simulate  $\epsilon \sim \MN(0, 1)$ (that we call shocks). These shocks, $\epsilon$, are embedded into diffusion (Eq. \ref{eq:genericsde}) as:

\begin{equation}
\textcolor{red}{dW(t) = \epsilon dt}
\end{equation}

\medskip

As \code{simdiff}, \code{simshocks} is written in C++ \textit{via} \code{Rcpp}. And when it comes to the simulation of multi-factors models, or the simulation of risk factors with flexible dependence structure, \code{simshocks} calls the underlying function \code{CDVinesim}, from package \href{http://cran.r-project.org/web/packages/CDVine/index.html}{CDVine}. \code{CDVineSim} makes simulations of canonical ({\bf C-vine}) and {\bf D-vine copulas}. 

\medskip

Simply put, a copula is a function which gives a multidimensional distribution to given margins. If $(X_1, \ldots, X_d)^T$ is a random vector with margins of cumulative distribution functions $F_1, \ldots, F_d$, there exists a copula  function $C$, such that the d-dimensional cumulative distribution function of $(X_1, \ldots, X_d)^T$ is :

\begin{equation}
F(x_1, \ldots, x_d) = C(F_1(x_1), \ldots, F_d(x_d))
\end{equation}


If the marginal distributions $F_1, \ldots, F_d$ are continuous, then $C$ is unique. On the other hand, if $C$ is a copula, and $F_1, \ldots, F_d$ are 1-dimensional cumulative distribution functions, the previous equation defines a joint cumulative distribution function for $(X_1, \ldots, X_d)^T$, with margins $F_1, \ldots, F_d$.

\medskip

Contrary to the multivariate Gaussian or Student-t copulas, vine copulas accurately model the dependence in high dimensions. They use the density functions of bivariate copulas (called pair-copula) to iteratively build a multivariate density function, which leads to a great flexibility in modeling the dependence.  

\medskip

\code{simshocks} applies inverse standard gaussian cumulative distribution function to the uniform margins of \code{CDVinesim} to obtains gaussian shocks, with various dependence structures between them. 

\medskip

\code{CDVineSim} can be used first, to choose the copula, and make an inference on it. Sometimes, the choice of the relevant copula is also made with expert knowledge. 

\medskip

\section{Examples}
\label{sec:examples}

The first section, \ref{sec:exampleshocks}, is related to \ref{sec:simshocks}. That is, to generating model shocks. Then, section \ref{sec:examplesimulation} presents a complete example of simulation using the package. 

\subsection{Generating dependent shocks $\epsilon$ with \code{simshocks}}
\label{sec:exampleshocks}

To use \code{simshocks}, you need the specify the number of simulations of $\epsilon$ that you need, \code{n}, the type of dependence, \code{family}, and additional parameters depending on the copula that you want to use. For a simulation of a Gaussian copula, \code{family} is \code{1} : 

<<chgt_package, warning=FALSE, message=FALSE>>=
library(ESGtoolkit)
@

<<example_simshocks_1>>=
# Number of simulations
nb <- 1000

# Number of risk factors
d <- 2

# Number of possible combinations of the risk factors (here : 1)
dd <- d*(d-1)/2

# Family : Gaussian copula 
fam1 <- rep(1, dd)

# Correlation coefficients between the risk factors (d*(d-1)/2)
par0_1 <- 0.1
par0_2 <- -0.9
@


A correlation coefficient is provided to \code{simshocks} through argument \code{par}:

<<example_simshocks_simul>>=
set.seed(2)

# Simulation of shocks for the d risk factors
s0_par1 <- simshocks(n = nb, horizon = 4, 
family = fam1, par = par0_1)

s0_par2 <- simshocks(n = nb, horizon = 4, 
family = fam1, par = par0_2)
@

You can make a correlation test with \code{esgcortest}, to assess whether correlation estimate is significantly close to the correlation you specified or not. If \code{esgcortest}'s confidence interval contains the true value at a given confidence level, the null hypothesis is not to be rejected at this level. 


<<example_simshocks_2>>=
# Correlation test
esgcortest(s0_par1)
@

These confidence intervals on the estimated correlations can also be visualized with \code{esgplotbands}:  

<<example_simshocks_3, fig.align='center', fig.height=4.5>>=
test <- esgcortest(s0_par2)
par(mfrow=c(1, 2))
esgplotbands(esgcortest(s0_par1))
esgplotbands(test)
@

Now with other types of dependences, namely rotated versions of the Clayton copula :

<<example_simshocks_4>>=
# Family : Rotated Clayton (180 degrees)
fam2 <- 13
par0_3 <- 2

# Family : Rotated Clayton (90 degrees)
fam3 <- 23
par0_4 <- -2

# number of simulations
nb <- 200

# Simulation of shocks for the d risk factors
s0_par3 <- simshocks(n = nb, horizon = 4, 
family = fam2, par = par0_3)

s0_par4 <- simshocks(n = nb, horizon = 4, 
family = fam3, par = par0_4)
@

There's a nice function from the package, \code{esgplotshocks}, that helps you in visualizing  dependence between shocks (inspired by \href{http://rforpublichealth.blogspot.fr/2014/02/ggplot2-cheatsheet-for-visualizing.html}{this blog post}) : 

<<example_simshocks_5, fig.align='center', fig.height=6>>=
esgplotshocks(s0_par3, s0_par4)
@

\newpage

\subsection{Example with \code{simdiff} and \code{simshocks} : Option pricing under the  Bates model (SVJD) for equity}
\label{sec:examplesimulation}

SVJD stands for Stochastic Volatility with Jump Diffusion. In this model, the volatility of the asset's price evolves as a CIR process. The price itself is a Geometric Brownian motion between jumps, arising from a Poisson process. Here, we consider jumps with lognormal magnitude.  

\medskip

{\bf The model}

\begin{eqnarray*}
dS(t) &=& (r - \lambda \mu_Z) S(t) dt + \sqrt{v(t)} S(t) dW(t)^{(1)} + (J - 1) dN(t)\\
dv(t) &=& \kappa(\theta - v(t)) dt + \sigma \sqrt{v(t)} dW(t)^{(2)}\\
dW(t)^{(1)} dW(t)^{(2)} &=& \rho dt
\end{eqnarray*}

We use the package \code{fOptions} to compute options' prices from market implied volatility : 
<<chgtfOptions, message=FALSE, warning=FALSE>>=
library(fOptions)
@

The parameters of Bates model are : 
<<<example_SVJD_1>>=
# Spot variance
V0 <- 0.1372
# mean-reversion speed
kappa <- 9.5110/100
# long-term variance
theta <- 0.0285
# volatility of volatility
volvol <- 0.8010/100
# Correlation between stoch. vol and prices
rho <- -0.5483
# Intensity of the Poisson process
lambda <- 0.3635
# mean and vol of the merton jumps diffusion
mu_J <- -0.2459
sigma_J <- 0.2547/100
m <- exp(mu_J + 0.5*(sigma_J^2)) - 1
# Initial stock price
S0 <- 4468.17
# Initial short rate
r0 <- 0.0357
@

Now we make \code{300} simulations of shocks and diffusions, on a weekly basis, from today, up to year 1. The shocks are simulated by using a variance reduction technique : antithetic variates (argument \code{method}). 

<<<example_SVJD_2>>=
n <- 300
horizon <- 1
freq <- "weekly" 

# Simulation of shocks, with antithetic variates
shocks <- simshocks(n = n, horizon = horizon, 
          frequency = freq, 
          method = "anti", 
          family = 1, par = rho)

# Vol simulation
sim_vol <- simdiff(n = n, horizon = horizon,
                   frequency = freq, model = "CIR", x0 = V0,
                   theta1 = kappa*theta, theta2 = kappa, 
                   theta3 = volvol,
                    eps = shocks[[1]])

# Plotting the volatility (only for a low number of simulations)
esgplotts(sim_vol)
@

Finally, the price's simulation takes {\bf exactly the same parameters} \code{n, horizon, frequency} as \code{simshocks} and \code{simdiff}, and the volatility is embedded through \code{theta2}.

<<<example_SVJD_price>>=
# prices simulation
sim_price <- simdiff(n = n, horizon = horizon,
                     frequency = freq, model = "GBM", x0 = S0,
                     theta1 = r0 - lambda*m, theta2 = sim_vol,
                     lambda = lambda, mu_z = mu_J, 
                     sigma_z = sigma_J, 
                     eps = shocks[[2]])
@

We can clearly see the prices jumping with \code{matplot}. But \code{esgplotbands}, offering a view of the paths by percentiles, will be more useful for thousands of simulations : 

<<<example_SVJD_4>>=
par(mfrow=c(2, 1))
matplot(time(sim_price), sim_price, type = 'l', 
        main = "with matplot")
esgplotbands(sim_price, main = "with esgplotbands", xlab = "time", 
             ylab = "values")
@

Now, we would like to verify the convergence of the estimated discounted prices to the initial asset price : 

\begin{equation}
\frac{1}{N}\sum_{i = 1}^N e^{-rT} S_T^{(i)} \longrightarrow \EE[e^{-rT}S_T] = S_0
\end{equation}

where $N$ is the number of simulations, $r$ is the constant risk free rate, and $T$ is a maturity of 2 weeks. 

<<<example_SVJD_3>>=
# Discounted Monte Carlo price
as.numeric(esgmcprices(r0, sim_price, 2/52))
# Inital price
S0
# pct. difference
as.numeric((esgmcprices(r0, sim_price, 2/52)/S0 - 1)*100)
@

One would also want to see how fast is the convergence towards $S0$ :
<<<example_SVJD_cvS0, fig.height=4>>=
# convergence of the discounted price
esgmccv(r0, sim_price, 2/52, 
        main = "Convergence towards the initial \n asset price")
@

\code{esgmcprices} and \code{esgmccv} give information about the mean, but a statistical test gives more information.  

<<<example_SVJD_martingale_1, results='hide'>>=
martingaletest_sim_price <- esgmartingaletest(r = r0, 
                                              X = sim_price, 
                                              p0 = S0)
@

\code{esgmartingaletest} computes for each $T$, a Student's t-test of 
$$H_0 : \EE[e^{-rT}S_T - S_0] = 0$$
versus the alternative hypothesis that the mean is not $0$, at a given confidence level (default is $95\%$).

\medskip

\code{esgmartingaletest} also provides p-values, and confidence intervals for the mean value. If all the confidence intervals contain $0$, then the null hypothesis is not rejected at the given level, let's say $95\%$. Which means that there are less than $5$ chances out of $100$ to be wrong by saying that the true mean of the distribution is $0$. 

\medskip
\code{esgplotbands} gives a visualization of the confidence intervals, as well as the average discounted prices. 

<<<example_SVJD_martingale_2>>=
esgplotbands(martingaletest_sim_price)
@

Now, we price a call option under the Bates model :

<<<example_pricing>>=
# Option pricing

# Strike
K <- 3400
Kts <- ts(matrix(K, nrow(sim_price), ncol(sim_price)), 
               start = start(sim_price), 
          deltat = deltat(sim_price),
          end = end(sim_price))

# Implied volatility
sigma_imp <- 0.6625

#Maturity
maturity <- 2/52

# payoff at maturity
payoff_ <- (sim_price - Kts)*(sim_price > Kts)
payoff <- window(payoff_, 
             start = deltat(sim_price), 
             deltat = deltat(sim_price),
             names = paste0("Series ", 1:n))

# True price
c0 <- GBSOption("c", S = S0, X = K, Time = maturity, r = r0, 
                b = 0, sigma = sigma_imp)
print(c0@price)

# Monte Carlo price
as.numeric(esgmcprices(r = r0, X = payoff, maturity))

# pct. difference
as.numeric((esgmcprices(r = r0, X = payoff, 
             maturity = maturity)/c0@price - 1)*100)

# Convergence towards the option price
esgmccv(r = r0, X = payoff, maturity = maturity, 
        main = "Convergence towards the call \n option price")
@

\newpage

\nocite{bates1996jumps}
\nocite{black1973pricing}
\nocite{brechmann2012risk}
\nocite{brechmann2013modeling}
\nocite{brigo2006interest}
\nocite{cox1985theory}
\nocite{eddelbuettel2011rcpp}
\nocite{glasserman2004monte}
\nocite{iacus2008simulation}
\nocite{kou2002jump}
\nocite{merton1976option}
\nocite{uhlenbeck1930theory}
\nocite{vasicek1977equilibrium}
\nocite{wickham2009ggplot2}
\bibliographystyle{jss}
\bibliography{mabiblio}

\end{document}